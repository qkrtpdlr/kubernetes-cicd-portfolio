# íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ì¸í”„ë¼ êµ¬ì¶• ë‹¨ê³„ ì´ìŠˆ](#ì¸í”„ë¼-êµ¬ì¶•-ë‹¨ê³„-ì´ìŠˆ)
2. [ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì´ìŠˆ](#ì• í”Œë¦¬ì¼€ì´ì…˜-ë°°í¬-ì´ìŠˆ)
3. [CI/CD íŒŒì´í”„ë¼ì¸ ì´ìŠˆ](#cicd-íŒŒì´í”„ë¼ì¸-ì´ìŠˆ)
4. [ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ìŠˆ](#ëª¨ë‹ˆí„°ë§-ì‹œìŠ¤í…œ-ì´ìŠˆ)
5. [ì„±ëŠ¥ ë° ìµœì í™”](#ì„±ëŠ¥-ë°-ìµœì í™”)

---

## ğŸ—ï¸ ì¸í”„ë¼ êµ¬ì¶• ë‹¨ê³„ ì´ìŠˆ

### Issue #1: EKS í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹¤íŒ¨

**ì¦ìƒ**
```
Error: error creating EKS Cluster: operation error EKS: CreateCluster
InvalidParameterException: Role arn:aws:iam::xxx:role/eks-cluster-role is not valid
```

**ì›ì¸**
- IAM Roleì˜ ì‹ ë¢° ê´€ê³„(Trust Policy)ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì§€ ì•ŠìŒ
- EKS ì„œë¹„ìŠ¤ ì ‘ê·¼ ê¶Œí•œ ë¶€ì¡±

**í•´ê²° ê³¼ì •**
```bash
# 1. IAM Role ì‹ ë¢° ê´€ê³„ í™•ì¸
aws iam get-role --role-name eks-cluster-role

# 2. Trust Policy ì—…ë°ì´íŠ¸
cat > trust-policy.json <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "eks.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
EOF

aws iam update-assume-role-policy \
  --role-name eks-cluster-role \
  --policy-document file://trust-policy.json

# 3. í•„ìˆ˜ ì •ì±… ì—°ê²° í™•ì¸
aws iam attach-role-policy \
  --role-name eks-cluster-role \
  --policy-arn arn:aws:iam::aws:policy/AmazonEKSClusterPolicy
```

**í•™ìŠµ ë‚´ìš©**
- IAM Roleì˜ ì‹ ë¢° ê´€ê³„ëŠ” "ëˆ„ê°€" ì—­í• ì„ ë§¡ì„ ìˆ˜ ìˆëŠ”ì§€ ì •ì˜
- EKS í´ëŸ¬ìŠ¤í„°ëŠ” `eks.amazonaws.com` ì„œë¹„ìŠ¤ê°€ ì—­í• ì„ ë§¡ì•„ì•¼ í•¨
- Terraformìœ¼ë¡œ ìë™í™”í•  ë•Œë„ ìˆœì„œê°€ ì¤‘ìš” (Role â†’ Policy â†’ Cluster)

**ì˜ˆë°© ì¡°ì¹˜**
```hcl
# terraform/iam.tf
resource "aws_iam_role" "eks_cluster_role" {
  name = "eks-cluster-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "eks.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "eks_cluster_policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role       = aws_iam_role.eks_cluster_role.name
}
```

---

### Issue #2: EKS ë…¸ë“œê°€ Ready ìƒíƒœê°€ ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**
```bash
kubectl get nodes
NAME                                      STATUS     ROLES    AGE   VERSION
ip-10-0-1-100.ap-northeast-2.compute...  NotReady   <none>   5m    v1.27.0
```

**ì›ì¸**
- VPC CNI í”ŒëŸ¬ê·¸ì¸ ë¯¸ì„¤ì¹˜
- Security Groupì—ì„œ ë…¸ë“œ ê°„ í†µì‹  ì°¨ë‹¨
- IAM Roleì— ë…¸ë“œ ì •ì±… ëˆ„ë½

**í•´ê²° ê³¼ì •**
```bash
# 1. CNI í”ŒëŸ¬ê·¸ì¸ í™•ì¸
kubectl get daemonset -n kube-system aws-node

# CNI ì—†ìœ¼ë©´ ì„¤ì¹˜
kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/release-1.12/config/master/aws-k8s-cni.yaml

# 2. Security Group ê·œì¹™ í™•ì¸
aws ec2 describe-security-groups \
  --group-ids sg-xxxxx \
  --query 'SecurityGroups[0].IpPermissions'

# 3. ë…¸ë“œ ê°„ í†µì‹  í—ˆìš© ê·œì¹™ ì¶”ê°€
aws ec2 authorize-security-group-ingress \
  --group-id sg-xxxxx \
  --protocol all \
  --source-group sg-xxxxx

# 4. ë…¸ë“œ ë¡œê·¸ í™•ì¸
kubectl logs -n kube-system -l k8s-app=aws-node
```

**í•™ìŠµ ë‚´ìš©**
- KubernetesëŠ” ë„¤íŠ¸ì›Œí¬ í”ŒëŸ¬ê·¸ì¸ ì—†ì´ëŠ” ë™ì‘ ë¶ˆê°€
- AWS EKSëŠ” VPC CNIë¥¼ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ í”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œ ì‚¬ìš©
- ë…¸ë“œ ê°„ í†µì‹ ì€ Security Groupì—ì„œ ìê¸° ìì‹ ì„ ì†ŒìŠ¤ë¡œ í—ˆìš©í•´ì•¼ í•¨

**ì˜ˆë°© ì¡°ì¹˜**
- Terraformì—ì„œ EKS ëª¨ë“ˆ ì‚¬ìš© ì‹œ ìë™ìœ¼ë¡œ CNI ì„¤ì¹˜ë¨
- Security Group ê·œì¹™ì„ ëª…ì‹œì ìœ¼ë¡œ ì •ì˜

---

### Issue #3: Terraform Apply ì¤‘ ë¦¬ì†ŒìŠ¤ ì˜ì¡´ì„± ì˜¤ë¥˜

**ì¦ìƒ**
```
Error: error creating EKS Node Group: InvalidParameterException: 
Subnets specified must exist
```

**ì›ì¸**
- Terraform ë¦¬ì†ŒìŠ¤ ìƒì„± ìˆœì„œ ë¬¸ì œ
- VPC/Subnetì´ ì™„ì „íˆ ìƒì„±ë˜ê¸° ì „ì— EKSê°€ ìƒì„± ì‹œë„

**í•´ê²° ê³¼ì •**
```hcl
# terraform/eks.tf
resource "aws_eks_cluster" "main" {
  # ëª…ì‹œì  ì˜ì¡´ì„± ì¶”ê°€
  depends_on = [
    aws_iam_role_policy_attachment.eks_cluster_policy,
    aws_subnet.private
  ]
  
  name     = var.cluster_name
  role_arn = aws_iam_role.eks_cluster_role.arn
  
  vpc_config {
    subnet_ids = aws_subnet.private[*].id
  }
}
```

**í•™ìŠµ ë‚´ìš©**
- Terraformì˜ ì•”ì‹œì  ì˜ì¡´ì„±(ì°¸ì¡°)ë§Œìœ¼ë¡œ ë¶€ì¡±í•œ ê²½ìš°ê°€ ìˆìŒ
- `depends_on`ìœ¼ë¡œ ëª…ì‹œì  ì˜ì¡´ì„± ì •ì˜ í•„ìš”
- ë³µì¡í•œ ì¸í”„ë¼ëŠ” ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ ë‹¨ê³„ì  ì ìš©

---

## ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì´ìŠˆ

### Issue #4: Pod ImagePullBackOff ì—ëŸ¬

**ì¦ìƒ**
```bash
kubectl get pods -n fresh-chicken
NAME                          READY   STATUS             RESTARTS   AGE
fresh-chicken-app-xxx         0/1     ImagePullBackOff   0          2m

kubectl describe pod fresh-chicken-app-xxx -n fresh-chicken
Failed to pull image "123456789012.dkr.ecr.ap-northeast-2.amazonaws.com/fresh-chicken:v1.0.0":
rpc error: code = Unknown desc = Error response from daemon: 
pull access denied for ..., repository does not exist or may require 'docker login'
```

**ì›ì¸**
- ECR ì¸ì¦ í† í° ë§Œë£Œ (12ì‹œê°„ ìœ íš¨)
- ServiceAccountì— ECR ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ
- ì´ë¯¸ì§€ íƒœê·¸ ì˜¤íƒ€ ë˜ëŠ” ì‹¤ì œë¡œ ì¡´ì¬í•˜ì§€ ì•ŠìŒ

**í•´ê²° ê³¼ì •**
```bash
# 1. ì´ë¯¸ì§€ ì¡´ì¬ í™•ì¸
aws ecr describe-images \
  --repository-name fresh-chicken \
  --region ap-northeast-2

# 2. ECR ë¡œê·¸ì¸ í™•ì¸
aws ecr get-login-password --region ap-northeast-2 | \
  docker login --username AWS --password-stdin \
  123456789012.dkr.ecr.ap-northeast-2.amazonaws.com

# 3. Kubernetes Secret ì¬ìƒì„±
kubectl delete secret ecr-secret -n fresh-chicken

kubectl create secret docker-registry ecr-secret \
  --docker-server=123456789012.dkr.ecr.ap-northeast-2.amazonaws.com \
  --docker-username=AWS \
  --docker-password=$(aws ecr get-login-password --region ap-northeast-2) \
  -n fresh-chicken

# 4. Deploymentì— imagePullSecrets ì¶”ê°€
kubectl patch deployment fresh-chicken-app -n fresh-chicken \
  --type='json' \
  -p='[{"op": "add", "path": "/spec/template/spec/imagePullSecrets", "value": [{"name": "ecr-secret"}]}]'
```

**ë” ë‚˜ì€ í•´ê²°ì±…: IRSA (IAM Roles for Service Accounts)**
```hcl
# terraform/irsa.tf
resource "aws_iam_role" "ecr_access" {
  name = "eks-ecr-access-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRoleWithWebIdentity"
      Effect = "Allow"
      Principal = {
        Federated = aws_iam_openid_connect_provider.eks.arn
      }
      Condition = {
        StringEquals = {
          "${replace(aws_iam_openid_connect_provider.eks.url, "https://", "")}:sub": 
          "system:serviceaccount:fresh-chicken:fresh-chicken-sa"
        }
      }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "ecr_access" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  role       = aws_iam_role.ecr_access.name
}
```

```yaml
# kubernetes/app/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fresh-chicken-sa
  namespace: fresh-chicken
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/eks-ecr-access-role
```

**í•™ìŠµ ë‚´ìš©**
- ECR ì¸ì¦ì€ 12ì‹œê°„ë§ˆë‹¤ ë§Œë£Œë˜ì–´ ìˆ˜ë™ ê´€ë¦¬ëŠ” ë¹„íš¨ìœ¨ì 
- IRSAë¥¼ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ í† í° ê°±ì‹  (ë³´ì•ˆ Best Practice)
- ServiceAccount ë‹¨ìœ„ë¡œ ì„¸ë¶„í™”ëœ ê¶Œí•œ ë¶€ì—¬ ê°€ëŠ¥

---

### Issue #5: CrashLoopBackOff - MySQL ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**
```bash
kubectl logs fresh-chicken-app-xxx -n fresh-chicken

com.mysql.cj.jdbc.exceptions.CommunicationsException: 
Communications link failure
The last packet sent successfully to the server was 0 milliseconds ago.
```

**ì›ì¸**
- MySQL Serviceê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ
- ConfigMapì˜ DB í˜¸ìŠ¤íŠ¸ëª… ì˜¤íƒ€
- MySQL Podê°€ ì‹¤í–‰ ì¤‘ì´ì§€ë§Œ ì´ˆê¸°í™” ì¤‘

**í•´ê²° ê³¼ì •**
```bash
# 1. MySQL Pod ìƒíƒœ í™•ì¸
kubectl get pods -l app=mysql -n fresh-chicken
kubectl logs mysql-xxx -n fresh-chicken

# 2. MySQL Service í™•ì¸
kubectl get svc mysql -n fresh-chicken
kubectl describe svc mysql -n fresh-chicken

# 3. ConfigMap í™•ì¸
kubectl get configmap fresh-chicken-config -n fresh-chicken -o yaml

# 4. ìˆ˜ë™ ì—°ê²° í…ŒìŠ¤íŠ¸
kubectl run mysql-client --rm -it --restart=Never \
  --image=mysql:8.0 -n fresh-chicken -- \
  mysql -h mysql.fresh-chicken.svc.cluster.local -u root -p

# 5. Deploymentì— initContainer ì¶”ê°€
```

```yaml
# kubernetes/app/deployment.yaml
spec:
  template:
    spec:
      initContainers:
      - name: wait-for-mysql
        image: busybox:1.35
        command: 
        - 'sh'
        - '-c'
        - |
          until nc -z mysql.fresh-chicken.svc.cluster.local 3306; do
            echo "Waiting for MySQL..."
            sleep 2
          done
          echo "MySQL is ready!"
      containers:
      - name: fresh-chicken-app
        # ... (ê¸°ì¡´ ì„¤ì •)
```

**í•™ìŠµ ë‚´ìš©**
- KubernetesëŠ” Pod ì‹œì‘ ìˆœì„œë¥¼ ë³´ì¥í•˜ì§€ ì•ŠìŒ
- initContainerë¡œ ì˜ì¡´ì„± ì²´í¬ ê°€ëŠ¥
- readinessProbeì™€ livenessProbeë¡œ í—¬ìŠ¤ì²´í¬ í•„ìˆ˜

**Best Practice**
```yaml
containers:
- name: fresh-chicken-app
  # ...
  livenessProbe:
    httpGet:
      path: /actuator/health/liveness
      port: 8080
    initialDelaySeconds: 60
    periodSeconds: 10
    
  readinessProbe:
    httpGet:
      path: /actuator/health/readiness
      port: 8080
    initialDelaySeconds: 30
    periodSeconds: 5
```

---

## ğŸ”„ CI/CD íŒŒì´í”„ë¼ì¸ ì´ìŠˆ

### Issue #6: Jenkins Pipeline - Gradle ë¹Œë“œ ì‹¤íŒ¨

**ì¦ìƒ**
```
[ERROR] Could not find or load main class org.gradle.wrapper.GradleWrapperMain
```

**ì›ì¸**
- Gitì— `gradle/wrapper/gradle-wrapper.jar` ì»¤ë°‹ ì•ˆ ë¨
- `.gitignore`ì—ì„œ wrapper jar ì œì™¸ë¨

**í•´ê²° ê³¼ì •**
```bash
# 1. .gitignore ìˆ˜ì •
# .gitignore
# Gradle
.gradle/
build/
!gradle/wrapper/gradle-wrapper.jar  # ì´ ì¤„ ì¶”ê°€

# 2. wrapper jar ë‹¤ì‹œ ì¶”ê°€
git add -f gradle/wrapper/gradle-wrapper.jar
git commit -m "Add Gradle wrapper jar"
git push

# 3. Jenkinsì—ì„œ ì¬ë¹Œë“œ
```

**í•™ìŠµ ë‚´ìš©**
- Gradle WrapperëŠ” ë¹Œë“œ í™˜ê²½ í†µì¼ì„ ìœ„í•´ jar íŒŒì¼ë„ ì»¤ë°‹í•´ì•¼ í•¨
- Jenkinsì—ì„œ Gradle ë¡œì»¬ ì„¤ì¹˜ ì—†ì´ `./gradlew` ì‚¬ìš© ê°€ëŠ¥

---

### Issue #7: Kaniko ë¹Œë“œ - "error building image: getting stage builder"

**ì¦ìƒ**
```
error building image: getting stage builder for stage 0: 
Get https://index.docker.io/v2/: dial tcp: lookup index.docker.io: 
no such host
```

**ì›ì¸**
- Jenkins Podì˜ DNS ì„¤ì • ë¬¸ì œ
- Kubernetes CoreDNS ì„œë¹„ìŠ¤ ì¥ì• 

**í•´ê²° ê³¼ì •**
```bash
# 1. CoreDNS ìƒíƒœ í™•ì¸
kubectl get pods -n kube-system -l k8s-app=kube-dns

# 2. Jenkins Pod DNS í…ŒìŠ¤íŠ¸
kubectl exec -it jenkins-xxx -n jenkins -- nslookup google.com

# 3. CoreDNS ì¬ì‹œì‘
kubectl rollout restart deployment coredns -n kube-system

# 4. Kaniko ë¹Œë“œì— DNS ì„œë²„ ëª…ì‹œ
```

```groovy
// Jenkinsfile
stage('Build Docker Image') {
    steps {
        container('kaniko') {
            sh '''
            /kaniko/executor \
              --context=dir://${WORKSPACE}/fresh-chicken-app \
              --dockerfile=Dockerfile \
              --destination=${ECR_REPO}:${IMAGE_TAG} \
              --cache=true \
              --dns=8.8.8.8  # Google DNS ì¶”ê°€
            '''
        }
    }
}
```

---

### Issue #8: ArgoCD - Application ë™ê¸°í™” ì‹¤íŒ¨

**ì¦ìƒ**
```
ComparisonError: Manifest generation error (cached): 
repository not found
```

**ì›ì¸**
- ArgoCDê°€ Private Repositoryì— ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ
- GitHub Token ë§Œë£Œ

**í•´ê²° ê³¼ì •**
```bash
# 1. GitHub Token ìƒì„± (repo ê¶Œí•œ í¬í•¨)

# 2. ArgoCDì— Repository ë“±ë¡
argocd repo add https://github.com/yourusername/kubernetes-cicd-infra.git \
  --username yourusername \
  --password ghp_xxxxxxxxxxxxx

# 3. ë˜ëŠ” SSH Key ì‚¬ìš©
ssh-keygen -t rsa -b 4096 -C "argocd@example.com"
# GitHubì— Deploy Key ë“±ë¡

argocd repo add git@github.com:yourusername/kubernetes-cicd-infra.git \
  --ssh-private-key-path ~/.ssh/id_rsa

# 4. Application ë™ê¸°í™” ì¬ì‹œë„
argocd app sync fresh-chicken
```

**í•™ìŠµ ë‚´ìš©**
- Private RepositoryëŠ” ì¸ì¦ í•„ìˆ˜
- Personal Access Tokenë³´ë‹¤ Deploy Keyê°€ ë³´ì•ˆìƒ ìœ ë¦¬
- ArgoCDëŠ” Git Repositoryë¥¼ "ì§„ì‹¤ì˜ ì›ì²œ(Source of Truth)"ìœ¼ë¡œ ì‚¬ìš©

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ìŠˆ

### Prometheusê°€ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ì§€ ëª»í•¨

**ì¦ìƒ**
- Grafana ëŒ€ì‹œë³´ë“œì— "No Data" í‘œì‹œ
- Prometheus Targetì´ "Down" ìƒíƒœ

**í•´ê²° ê³¼ì •**
```bash
# 1. ServiceMonitor í™•ì¸
kubectl get servicemonitor -n monitoring

# 2. Prometheusê°€ ServiceMonitorë¥¼ ì¸ì‹í•˜ëŠ”ì§€ í™•ì¸
kubectl logs -n monitoring prometheus-xxx

# 3. Serviceì— ì˜¬ë°”ë¥¸ Label ì¶”ê°€
kubectl label service fresh-chicken-service -n fresh-chicken \
  prometheus.io/scrape=true \
  prometheus.io/port=8080 \
  prometheus.io/path=/actuator/prometheus
```

---

## ğŸ¯ ì„±ëŠ¥ ë° ìµœì í™”

### HPAê°€ ìŠ¤ì¼€ì¼ë§í•˜ì§€ ì•ŠìŒ

**í•´ê²° ê³¼ì •**
```bash
# Metrics Server ì„¤ì¹˜
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# HPA ìƒíƒœ í™•ì¸
kubectl get hpa -n fresh-chicken
kubectl describe hpa fresh-chicken-hpa -n fresh-chicken
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Kubernetes ê³µì‹ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](https://kubernetes.io/docs/tasks/debug/)
- [AWS EKS ë¬¸ì œ í•´ê²° ê°€ì´ë“œ](https://docs.aws.amazon.com/eks/latest/userguide/troubleshooting.html)
- [ArgoCD FAQ](https://argo-cd.readthedocs.io/en/stable/faq/)
